<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GetLLM - Prezentacja PDF</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap');
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&display=swap');

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: #f8fafc;
            color: #1a202c;
            line-height: 1.6;
        }

        @media print {
            body {
                background: white;
                color: black;
            }
            .no-print {
                display: none !important;
            }
            .slide {
                page-break-after: always;
                box-shadow: none !important;
                border: 1px solid #e2e8f0;
            }
            .slide:last-child {
                page-break-after: auto;
            }
        }

        .presentation-wrapper {
            max-width: 210mm;
            margin: 0 auto;
            padding: 20px;
            background: white;
        }

        .slide {
            width: 100%;
            min-height: 297mm;
            background: white;
            margin: 0 0 30px 0;
            padding: 40px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
            border-radius: 8px;
            position: relative;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }

        .slide-header {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 8px;
            background: linear-gradient(90deg, #667eea, #764ba2);
        }

        .slide-number {
            position: absolute;
            top: 20px;
            right: 30px;
            background: #667eea;
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 12px;
            font-weight: 600;
        }

        .slide-footer {
            position: absolute;
            bottom: 20px;
            left: 30px;
            right: 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 11px;
            color: #64748b;
            border-top: 1px solid #e2e8f0;
            padding-top: 15px;
        }

        h1 {
            font-size: 3.5rem;
            font-weight: 800;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            text-align: center;
            margin-bottom: 30px;
            line-height: 1.2;
        }

        h2 {
            font-size: 2.2rem;
            font-weight: 700;
            color: #2d3748;
            text-align: center;
            margin-bottom: 40px;
            line-height: 1.3;
        }

        h3 {
            font-size: 1.5rem;
            font-weight: 600;
            color: #4a5568;
            margin: 30px 0 20px 0;
        }

        h4 {
            font-size: 1.2rem;
            font-weight: 600;
            color: #667eea;
            margin-bottom: 15px;
        }

        p {
            font-size: 1.1rem;
            color: #4a5568;
            margin-bottom: 20px;
            line-height: 1.7;
        }

        .subtitle {
            font-size: 1.3rem;
            color: #64748b;
            text-align: center;
            font-weight: 400;
            margin-bottom: 50px;
            line-height: 1.5;
        }

        .logo-section {
            text-align: center;
            margin: 40px 0;
        }

        .logo {
            font-size: 4rem;
            font-weight: 800;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 20px;
            letter-spacing: -2px;
        }

        .content-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .feature-card {
            background: linear-gradient(135deg, #f8faff, #eef2ff);
            border-radius: 12px;
            padding: 25px;
            border-left: 4px solid #667eea;
            box-shadow: 0 2px 10px rgba(102, 126, 234, 0.1);
        }

        .feature-card h4 {
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }

        .feature-card p {
            margin: 0;
            font-size: 1rem;
            color: #64748b;
        }

        .code-block {
            background: #1e293b;
            color: #e2e8f0;
            padding: 25px;
            border-radius: 8px;
            margin: 25px 0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
            border-left: 4px solid #667eea;
            overflow-x: auto;
        }

        .code-comment {
            color: #94a3b8;
        }

        .highlight-box {
            background: linear-gradient(135deg, #dbeafe, #bfdbfe);
            border: 2px solid #3b82f6;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
        }

        .warning-box {
            background: linear-gradient(135deg, #fef2f2, #fecaca);
            border: 2px solid #ef4444;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
        }

        .warning-box h4 {
            color: #dc2626;
            margin-bottom: 15px;
        }

        .success-box {
            background: linear-gradient(135deg, #f0fdf4, #dcfce7);
            border: 2px solid #22c55e;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
        }

        .success-box h4 {
            color: #16a34a;
            margin-bottom: 15px;
        }

        .ecosystem-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 20px;
            margin: 30px 0;
        }

        .ecosystem-item {
            background: #667eea;
            color: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            font-size: 0.9rem;
        }

        .ecosystem-item h5 {
            font-size: 1rem;
            margin-bottom: 8px;
            font-weight: 600;
        }

        .command-list {
            display: grid;
            grid-template-columns: 1fr;
            gap: 15px;
            margin: 20px 0;
        }

        .command-item {
            background: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            padding: 15px;
            font-family: 'JetBrains Mono', monospace;
        }

        .command-title {
            font-size: 0.85rem;
            color: #667eea;
            font-weight: 600;
            margin-bottom: 5px;
            font-family: 'Inter', sans-serif;
        }

        .command-code {
            font-size: 0.9rem;
            color: #1e293b;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 20px;
            margin: 30px 0;
        }

        .stat-item {
            text-align: center;
            padding: 20px;
            background: #f8fafc;
            border-radius: 10px;
            border: 1px solid #e2e8f0;
        }

        .stat-number {
            font-size: 2rem;
            font-weight: 700;
            color: #667eea;
            display: block;
        }

        .stat-label {
            font-size: 0.9rem;
            color: #64748b;
            margin-top: 5px;
        }

        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 40px;
            margin: 30px 0;
        }

        .author-section {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 30px;
            border-radius: 15px;
            text-align: center;
            margin: 40px 0;
        }

        .author-section h3 {
            color: white;
            margin-bottom: 20px;
        }

        .author-section p {
            color: rgba(255,255,255,0.9);
            margin-bottom: 15px;
        }

        .badges {
            display: flex;
            justify-content: center;
            gap: 15px;
            flex-wrap: wrap;
            margin-top: 20px;
        }

        .badge {
            background: rgba(255,255,255,0.2);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 500;
        }

        .print-button {
            position: fixed;
            top: 20px;
            right: 20px;
            background: #667eea;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 25px;
            font-weight: 600;
            cursor: pointer;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
            z-index: 1000;
            font-size: 14px;
        }

        .print-button:hover {
            background: #5a67d8;
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }

        @media (max-width: 768px) {
            .slide {
                padding: 20px;
                min-height: auto;
            }

            h1 { font-size: 2.5rem; }
            h2 { font-size: 1.8rem; }

            .content-grid {
                grid-template-columns: 1fr;
                gap: 20px;
            }

            .ecosystem-grid {
                grid-template-columns: repeat(2, 1fr);
            }

            .stats-grid {
                grid-template-columns: repeat(2, 1fr);
            }

            .two-column {
                grid-template-columns: 1fr;
                gap: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="presentation-wrapper">

        <!-- Slajd 1: Strona tytułowa -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">1 / 10</div>

            <div class="logo-section">
                <div class="logo">GetLLM</div>
                <h1>Zarządzanie modelami LLM z integracją Ollama</h1>
                <p class="subtitle">Python package dla efektywnego zarządzania modelami AI i generowania kodu Python<br>
                Część ekosystemu PyLama</p>
            </div>

            <div class="highlight-box">
                <h4>🎯 Kluczowe Cechy</h4>
                <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; margin-top: 20px;">
                    <div>
                        <strong>🤖 Generowanie Kodu</strong><br>
                        <small>Automatyczne tworzenie kodu Python</small>
                    </div>
                    <div>
                        <strong>📦 Zarządzanie Modelami</strong><br>
                        <small>Instalacja i konfiguracja modeli AI</small>
                    </div>
                    <div>
                        <strong>🔗 Integracja HuggingFace</strong><br>
                        <small>Bezpośredni dostęp do tysięcy modeli</small>
                    </div>
                    <div>
                        <strong>🇵🇱 Wsparcie Bielik</strong><br>
                        <small>Specjalna obsługa polskich modeli</small>
                    </div>
                </div>
            </div>

            <div class="slide-footer">
                <div>GetLLM - Presentation</div>
                <div>py-lama.github.io/getllm</div>
            </div>
        </div>

        <!-- Slajd 2: Problem i Rozwiązanie -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">2 / 10</div>

            <h2>Problem i Rozwiązanie</h2>

            <div class="two-column">
                <div>
                    <div class="warning-box">
                        <h4>⚠️ Wyzwania w zarządzaniu LLM</h4>
                        <p><strong>Skomplikowana instalacja</strong><br>
                        Różne formaty modeli, zależności, konfiguracje</p>

                        <p><strong>Problemy z kompatybilnością</strong><br>
                        Różne API, timeout, problemy z zasobami</p>

                        <p><strong>Brak centralnego zarządzania</strong><br>
                        Rozproszone konfiguracje, brak spójności</p>

                        <p><strong>Trudności z polskimi modelami</strong><br>
                        Specjalne wymagania, różne sources</p>
                    </div>
                </div>

                <div>
                    <div class="success-box">
                        <h4>✅ GetLLM jako rozwiązanie</h4>
                        <p><strong>Tryb interaktywny</strong><br>
                        Stabilny interfejs menu z nawigacją</p>

                        <p><strong>Automatyczna instalacja</strong><br>
                        Auto-detect, auto-install, auto-configure</p>

                        <p><strong>Integracja z ekosystemem</strong><br>
                        Centralne logowanie przez LogLama</p>

                        <p><strong>Specjalne wsparcie Bielik</strong><br>
                        Dedykowane funkcje dla polskich modeli</p>
                    </div>
                </div>
            </div>

            <div class="highlight-box">
                <h4>💡 Główne przesłanie</h4>
                <p style="text-align: center; font-size: 1.2rem; margin: 0;">
                    <strong>GetLLM przekształca skomplikowane zarządzanie modelami AI w prosty, interaktywny proces</strong>
                </p>
            </div>

            <div class="slide-footer">
                <div>GetLLM - Problem & Solution</div>
                <div>Tom Sapletta - DevOps Engineer</div>
            </div>
        </div>

        <!-- Slajd 3: Ekosystem PyLama -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">3 / 10</div>

            <h2>Ekosystem PyLama</h2>
            <p style="text-align: center; margin-bottom: 40px;">GetLLM jest integralną częścią kompleksowego ekosystemu narzędzi do automatyzacji rozwoju oprogramowania</p>

            <div class="ecosystem-grid">
                <div class="ecosystem-item">
                    <h5>🤖 GetLLM</h5>
                    <p>Zarządzanie modelami LLM i generowanie kodu Python</p>
                </div>
                <div class="ecosystem-item">
                    <h5>🐍 DevLama</h5>
                    <p>Generowanie kodu Python z Ollama</p>
                </div>
                <div class="ecosystem-item">
                    <h5>📝 LogLama</h5>
                    <p>Centralne logowanie i zarządzanie środowiskiem</p>
                </div>
                <div class="ecosystem-item">
                    <h5>🌐 APILama</h5>
                    <p>Serwis API dla generowania kodu</p>
                </div>
                <div class="ecosystem-item">
                    <h5>📦 BEXY</h5>
                    <p>Sandbox do wykonywania wygenerowanego kodu</p>
                </div>
                <div class="ecosystem-item">
                    <h5>⚡ JSLama</h5>
                    <p>Generowanie kodu JavaScript</p>
                </div>
                <div class="ecosystem-item">
                    <h5>📦 JSBox</h5>
                    <p>JavaScript sandbox dla wykonywania kodu</p>
                </div>
                <div class="ecosystem-item">
                    <h5>🐚 SheLLama</h5>
                    <p>Generowanie komend shell i operacje systemowe</p>
                </div>
                <div class="ecosystem-item">
                    <h5>🌍 WebLama</h5>
                    <p>Generowanie aplikacji webowych</p>
                </div>
            </div>

            <div class="highlight-box">
                <h4>🔗 Integracja z LogLama</h4>
                <p><strong>Centralne zarządzanie środowiskiem:</strong> Zmienne z .env w katalogu devlama</p>
                <p><strong>Współdzielona konfiguracja:</strong> Ustawienia modeli dostępne dla wszystkich komponentów</p>
                <p><strong>Strukturalne logowanie:</strong> Wszystkie operacje logowane z kontekstem komponentów</p>
            </div>

            <div class="slide-footer">
                <div>PyLama Ecosystem</div>
                <div>github.com/py-lama</div>
            </div>
        </div>

        <!-- Slajd 4: Główne Funkcje -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">4 / 10</div>

            <h2>Główne Funkcje GetLLM</h2>

            <div class="content-grid">
                <div class="feature-card">
                    <h4>🤖 Generowanie Kodu</h4>
                    <p>Automatyczne generowanie kodu Python przy użyciu zaawansowanych modeli LLM z pełnym kontekstem platformy i zależności</p>
                </div>

                <div class="feature-card">
                    <h4>📦 Zarządzanie Modelami</h4>
                    <p>Kompletne zarządzanie cyklem życia modeli: instalacja, aktualizacja, konfiguracja i wybór domyślnych modeli</p>
                </div>

                <div class="feature-card">
                    <h4>🔗 Integracja HuggingFace</h4>
                    <p>Bezpośrednie wyszukiwanie, przeglądanie i instalacja modeli z największego repozytorium modeli AI na świecie</p>
                </div>

                <div class="feature-card">
                    <h4>⚡ Auto-instalacja</h4>
                    <p>Inteligentna automatyczna instalacja modeli gdy nie są dostępne, z mechanizmami fallback i retry</p>
                </div>

                <div class="feature-card">
                    <h4>🔄 Mechanizmy Fallback</h4>
                    <p>Automatyczne przełączanie na modele zapasowe przy problemach z dostępnością lub zasobami systemowymi</p>
                </div>

                <div class="feature-card">
                    <h4>💬 Tryb Interaktywny</h4>
                    <p>Przyjazny interfejs CLI z menu nawigacyjnym, zapewniający stabilne i intuitive zarządzanie modelami</p>
                </div>

                <div class="feature-card">
                    <h4>⚙️ Konfiguracja Środowiska</h4>
                    <p>Elastyczna konfiguracja Ollama przez zmienne środowiskowe z integracją z centralnym systemem .env</p>
                </div>

                <div class="feature-card">
                    <h4>🎭 Tryb Mock</h4>
                    <p>Możliwość pracy bez wymagania zainstalowanego Ollama - idealne do testowania i rozwoju</p>
                </div>

                <div class="feature-card">
                    <h4>📝 System Szablonów</h4>
                    <p>Zaawansowany system generowania kodu z uwzględnieniem platformy, zależności i kontekstu projektu</p>
                </div>
            </div>

            <div class="slide-footer">
                <div>GetLLM Features</div>
                <div>Comprehensive LLM Management</div>
            </div>
        </div>

        <!-- Slajd 5: Tryb Interaktywny -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">5 / 10</div>

            <h2>Tryb Interaktywny - Zalecane Użycie</h2>

            <div class="warning-box">
                <h4>⚠️ Znane Problemy z Bezpośrednim Generowaniem</h4>
                <p><strong>Problem:</strong> Komendy typu <code>getllm "create a function"</code> mają problemy timeout z API Ollama</p>
                <div style="margin-top: 15px;">
                    <strong>Przyczyny:</strong>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>Model za duży dla dostępnych zasobów systemowych</li>
                        <li>Serwer Ollama zajęty innymi żądaniami lub procesami</li>
                        <li>Prompt wymaga zbyt dużo czasu przetwarzania</li>
                        <li>Problemy z konfiguracją timeout w API</li>
                    </ul>
                </div>
            </div>

            <div class="success-box">
                <h4>✅ Rozwiązanie: Tryb Interaktywny</h4>
                <p><strong>Komenda:</strong> <code>getllm -i</code></p>
                <p>Zapewnia stabilny interfejs do generowania kodu i zarządzania modelami z pełną kontrolą nad procesem.</p>
            </div>

            <div class="code-block">
<span class="code-comment"># Zamiast problematycznego bezpośredniego generowania:</span>
getllm "create a function"  <span class="code-comment"># ❌ Problemy timeout</span>

<span class="code-comment"># Używaj zawsze trybu interaktywnego:</span>
getllm -i                   <span class="code-comment"># ✅ Stabilne działanie</span>

<span class="code-comment"># Opcjonalnie z trybem mock:</span>
getllm -i --mock            <span class="code-comment"># ✅ Bez wymagania Ollama</span>
            </div>

            <div class="highlight-box">
                <h4>🎮 Menu Interaktywne</h4>
                <div style="background: #1e293b; color: #e2e8f0; padding: 20px; border-radius: 8px; font-family: 'JetBrains Mono', monospace; font-size: 0.85rem; margin-top: 15px;">
+--------------------------------+<br>
|  getllm - tryb interaktywny    |<br>
+--------------------------------+<br>
| > Lista dostępnych modeli      |<br>
|   Pokaż domyślny model        |<br>
|   Lista zainstalowanych modeli |<br>
|   Instaluj model              |<br>
|   Ustaw domyślny model        |<br>
|   Wyszukaj modele Bielik       |<br>
|   Testuj domyślny model       |<br>
|   Wyjście                     |<br>
+--------------------------------+<br>
  (nawigacja: strzałki + Enter)
                </div>
            </div>

            <div class="slide-footer">
                <div>Interactive Mode</div>
                <div>Recommended Usage Pattern</div>
            </div>
        </div>

        <!-- Slajd 6: Wsparcie dla Modeli Bielik -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">6 / 10</div>

            <h2>🇵🇱 Specjalne Wsparcie dla Modeli Bielik</h2>

            <div class="highlight-box">
                <h4>🎯 SpeakLeash Bielik Models</h4>
                <p>GetLLM oferuje pierwszorzędne wsparcie dla polskich modeli AI od SpeakLeash z automatyczną konfiguracją i optymalizacją.</p>
            </div>

            <div class="content-grid">
                <div class="feature-card">
                    <h4>🔍 Automatyczne Wykrycie</h4>
                    <p>System automatycznie rozpoznaje modele SpeakLeash Bielik i stosuje odpowiednie ustawienia instalacji i konfiguracji</p>
                </div>

                <div class="feature-card">
                    <h4>⏱️ Optymalizacja Timeout</h4>
                    <p>Automatyczne zwiększenie timeout API do 120 sekund dla większych polskich modeli zapewniając stabilne działanie</p>
                </div>

                <div class="feature-card">
                    <h4>⚙️ Auto-konfiguracja</h4>
                    <p>Automatyczna aktualizacja pliku .env z optymalnymi ustawieniami dla modeli Bielik bez ingerencji użytkownika</p>
                </div>

                <div class="feature-card">
                    <h4>🔄 Zarządzanie Istniejącymi</h4>
                    <p>Inteligentne wykrywanie już zainstalowanych wersji modeli Bielik i ich ponowne wykorzystanie</p>
                </div>
            </div>

            <div class="code-block">
<span class="code-comment"># Wyszukiwanie polskich modeli Bielik</span>
getllm --search bielik

<span class="code-comment"># Przykład wyszukiwania - modele SpeakLeash:</span>
speakleash/Bielik-11B-v2.3-Instruct-FP8      Downloads: 26,103
speakleash/Bielik-1.5B-v3.0-Instruct-GGUF    Downloads: 423
speakleash/Bielik-4.5B-v3.0-Instruct-GGUF    Downloads: 967
speakleash/Bielik-7B-Instruct-v0.1-GGUF      Downloads: 712

<span class="code-comment"># Automatyczna instalacja z konfiguracją:</span>
Wykryto model SpeakLeash Bielik: speakleash/Bielik-1.5B-v3.0-Instruct-GGUF
Uruchamianie procesu specjalnej instalacji...
✓ Znaleziono istniejący model: bielik-custom-1747866289:latest
✓ Zwiększono timeout API do 120 sekund dla modelu Bielik
✓ Zaktualizowano .env z ustawieniami modelu
            </div>

            <div class="stats-grid">
                <div class="stat-item">
                    <span class="stat-number">20+</span>
                    <div class="stat-label">Modeli Bielik</div>
                </div>
                <div class="stat-item">
                    <span class="stat-number">120s</span>
                    <div class="stat-label">Timeout API</div>
                </div>
                <div class="stat-item">
                    <span class="stat-number">Auto</span>
                    <div class="stat-label">Konfiguracja</div>
                </div>
                <div class="stat-item">
                    <span class="stat-number">🇵🇱</span>
                    <div class="stat-label">Polish AI</div>
                </div>
            </div>

            <div class="slide-footer">
                <div>Bielik Models Support</div>
                <div>Polish AI Innovation</div>
            </div>
        </div>

        <!-- Slajd 7: Podstawowe Komendy -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">7 / 10</div>

            <h2>Podstawowe Komendy i Użycie</h2>

            <div class="success-box">
                <h4>✅ Zalecane Podejście</h4>
                <p><strong>Tryb interaktywny</strong> jest obecnie najbardziej stabilną metodą pracy z GetLLM. Zapewnia pełną kontrolę nad procesem i eliminuje problemy z timeout.</p>
            </div>

            <h3>🚀 Podstawowe Zarządzanie</h3>
            <div class="command-list">
                <div class="command-item">
                    <div class="command-title">Tryb interaktywny (ZALECANE)</div>
                    <div class="command-code">getllm -i</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Tryb interaktywny z mock</div>
                    <div class="command-code">getllm -i --mock</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Lista dostępnych modeli</div>
                    <div class="command-code">getllm list</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Lista zainstalowanych modeli</div>
                    <div class="command-code">getllm installed</div>
                </div>
            </div>

            <h3>🔧 Zarządzanie Modelami</h3>
            <div class="command-list">
                <div class="command-item">
                    <div class="command-title">Instalacja modelu</div>
                    <div class="command-code">getllm install codellama:7b</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Ustawienie domyślnego modelu</div>
                    <div class="command-code">getllm set-default codellama:7b</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Sprawdzenie domyślnego modelu</div>
                    <div class="command-code">getllm default</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Aktualizacja listy z Ollama</div>
                    <div class="command-code">getllm update</div>
                </div>
            </div>

            <h3>🔍 Integracja z HuggingFace</h3>
            <div class="command-list">
                <div class="command-item">
                    <div class="command-title">Wyszukiwanie modeli (np. polskich Bielik)</div>
                    <div class="command-code">getllm --search bielik</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Aktualizacja listy z HuggingFace</div>
                    <div class="command-code">getllm --update-hf</div>
                </div>
            </div>

            <div class="slide-footer">
                <div>Basic Commands</div>
                <div>Always use: getllm -i</div>
            </div>
        </div>

        <!-- Slajd 8: Instalacja i Konfiguracja -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">8 / 10</div>

            <h2>Instalacja i Konfiguracja</h2>

            <h3>📦 Instalacja w Środowisku Deweloperskim</h3>
            <div class="code-block">
<span class="code-comment"># Utworzenie wirtualnego środowiska</span>
python -m venv venv
source venv/bin/activate  <span class="code-comment"># Windows: venv\Scripts\activate</span>

<span class="code-comment"># WAŻNE: Zawsze instaluj w trybie deweloperskim!</span>
pip install -e .

<span class="code-comment"># Weryfikacja instalacji</span>
getllm --help
            </div>

            <h3>🛠️ Makefile - Uproszczone Zarządzanie</h3>
            <div class="command-list">
                <div class="command-item">
                    <div class="command-title">Konfiguracja projektu (venv + dependencies)</div>
                    <div class="command-code">make setup</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Uruchomienie serwera API (port 8001)</div>
                    <div class="command-code">make run</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Uruchomienie na niestandardowym porcie</div>
                    <div class="command-code">make run PORT=8080</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Uruchomienie testów</div>
                    <div class="command-code">make test</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Formatowanie kodu z Black</div>
                    <div class="command-code">make format</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Analiza kodu z Flake8</div>
                    <div class="command-code">make lint</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Czyszczenie cache i plików tymczasowych</div>
                    <div class="command-code">make clean</div>
                </div>

                <div class="command-item">
                    <div class="command-title">Wyświetlenie wszystkich dostępnych komend</div>
                    <div class="command-code">make help</div>
                </div>
            </div>

            <h3>⚙️ Kluczowe Pliki Projektu</h3>
            <div class="content-grid">
                <div class="feature-card">
                    <h4>📄 getllm/cli.py</h4>
                    <p>Główny interfejs linii komend z wszystkimi dostępnymi opcjami</p>
                </div>

                <div class="feature-card">
                    <h4>💬 getllm/interactive_cli.py</h4>
                    <p>Tryb interaktywny z menu nawigacyjnym i wyborem kursorem</p>
                </div>

                <div class="feature-card">
                    <h4>🔧 getllm/models.py</h4>
                    <p>Logika zarządzania modelami, obsługa .env i integracja z Ollama</p>
                </div>

                <div class="feature-card">
                    <h4>⚙️ .env/env.example</h4>
                    <p>Konfiguracja środowiska i ustawienia domyślnych modeli</p>
                </div>
            </div>

            <div class="slide-footer">
                <div>Installation & Configuration</div>
                <div>Always: pip install -e .</div>
            </div>
        </div>

        <!-- Slajd 9: Zmienne Środowiskowe -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">9 / 10</div>

            <h2>Zmienne Środowiskowe i Konfiguracja</h2>

            <p>GetLLM używa następujących zmiennych środowiskowych do konfiguracji integracji z Ollama:</p>

            <div class="command-list">
                <div class="command-item">
                    <div class="command-title">OLLAMA_PATH</div>
                    <div class="command-code">Ścieżka do pliku wykonywalnego Ollama (domyślnie: 'ollama')</div>
                </div>

                <div class="command-item">
                    <div class="command-title">OLLAMA_MODEL</div>
                    <div class="command-code">Domyślny model do użycia (domyślnie: 'codellama:7b')</div>
                </div>

                <div class="command-item">
                    <div class="command-title">OLLAMA_FALLBACK_MODELS</div>
                    <div class="command-code">Lista modeli zapasowych oddzielonych przecinkami<br>(domyślnie: 'codellama:7b,phi3:latest,tinyllama:latest')</div>
                </div>

                <div class="command-item">
                    <div class="command-title">OLLAMA_AUTO_SELECT_MODEL</div>
                    <div class="command-code">Automatyczny wybór dostępnego modelu gdy żądany nie jest znaleziony<br>(domyślnie: 'true')</div>
                </div>

                <div class="command-item">
                    <div class="command-title">OLLAMA_AUTO_INSTALL_MODEL</div>
                    <div class="command-code">Automatyczna instalacja modelu gdy nie jest znaleziony<br>(domyślnie: 'true')</div>
                </div>

                <div class="command-item">
                    <div class="command-title">OLLAMA_TIMEOUT</div>
                    <div class="command-code">Timeout API w sekundach (domyślnie: '30', Bielik: '120')</div>
                </div>
            </div>

            <h3>📝 Przykład pliku .env</h3>
            <div class="code-block">
<span class="code-comment"># Przykładowa konfiguracja .env dla GetLLM</span>
OLLAMA_PATH=ollama
OLLAMA_MODEL=codellama:7b
OLLAMA_FALLBACK_MODELS=codellama:7b,phi3:latest,tinyllama:latest
OLLAMA_AUTO_SELECT_MODEL=true
OLLAMA_AUTO_INSTALL_MODEL=true
OLLAMA_TIMEOUT=30

<span class="code-comment"># Specjalna konfiguracja dla modeli Bielik (automatyczna)</span>
OLLAMA_MODEL=bielik-custom-1747866289:latest
OLLAMA_TIMEOUT=120
            </div>

            <div class="highlight-box">
                <h4>💡 Wskazówki Konfiguracyjne</h4>
                <p><strong>Lokalizacja:</strong> Zmienne można ustawić w pliku .env w katalogu głównym projektu lub w środowisku systemowym</p>
                <p><strong>Priorytet:</strong> Zmienne środowiskowe systemu mają priorytet nad plikiem .env</p>
                <p><strong>Automatyczna aktualizacja:</strong> GetLLM automatycznie aktualizuje .env przy instalacji modeli Bielik</p>
            </div>

            <div class="slide-footer">
                <div>Environment Variables</div>
                <div>Flexible Configuration</div>
            </div>
        </div>

        <!-- Slajd 10: Podsumowanie i Kontakt -->
        <div class="slide">
            <div class="slide-header"></div>
            <div class="slide-number">10 / 10</div>

            <h2>Podsumowanie i Kontakt</h2>

            <div class="two-column">
                <div>
                    <h3>🎯 Kluczowe Zalety GetLLM</h3>
                    <ul style="font-size: 1rem; line-height: 1.8; color: #4a5568;">
                        <li><strong>Tryb interaktywny</strong> - stabilne zarządzanie modelami</li>
                        <li><strong>Wsparcie Bielik</strong> - dedykowane funkcje dla polskich modeli</li>
                        <li><strong>Automatyzacja</strong> - auto-install, auto-configure</li>
                        <li><strong>Integracja HuggingFace</strong> - dostęp do tysięcy modeli</li>
                        <li><strong>Ekosystem PyLama</strong> - część większego rozwiązania</li>
                        <li><strong>Fallback mechanisms</strong> - niezawodność działania</li>
                    </ul>

                    <div class="highlight-box" style="margin-top: 30px;">
                        <h4>💡 Główne Zalecenie</h4>
                        <p style="text-align: center; font-size: 1.3rem; margin: 0;">
                            <strong>Zawsze używaj: <code>getllm -i</code></strong>
                        </p>
                    </div>
                </div>

                <div>
                    <h3>🔗 Przydatne Linki</h3>
                    <div class="command-list">
                        <div class="command-item">
                            <div class="command-title">🌐 Strona główna</div>
                            <div class="command-code">py-lama.github.io/getllm</div>
                        </div>

                        <div class="command-item">
                            <div class="command-title">💻 Kod źródłowy</div>
                            <div class="command-code">github.com/py-lama/getllm</div>
                        </div>

                        <div class="command-item">
                            <div class="command-title">📦 PyPI Package</div>
                            <div class="command-code">pypi.org/project/getllm</div>
                        </div>

                        <div class="command-item">
                            <div class="command-title">📚 Dokumentacja</div>
                            <div class="command-code">py-lama.github.io/getllm/docs</div>
                        </div>
                    </div>

                    <h3>💰 Wsparcie Projektu</h3>
                    <div class="command-list">
                        <div class="command-item">
                            <div class="command-title">GitHub Sponsors</div>
                            <div class="command-code">github.com/sponsors/tom-sapletta-com</div>
                        </div>

                        <div class="command-item">
                            <div class="command-title">Open Collective</div>
                            <div class="command-code">opencollective.com/tom-sapletta-com</div>
                        </div>

                        <div class="command-item">
                            <div class="command-title">PayPal</div>
                            <div class="command-code">paypal.me/softreck/10.00</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="author-section">
                <h3>👨‍💻 Autor</h3>
                <p><strong>Tom Sapletta</strong> — DevOps Engineer & Systems Architect</p>
                <p>💻 15+ lat doświadczenia w DevOps, Software Development i Systems Architecture</p>
                <p>🏢 Founder & CEO w Telemonit (Portigen - edge computing power solutions)</p>
                <p>🌍 Niemcy | Otwarty na zdalną współpracę</p>
                <p>📚 Pasjonuje się edge computing, hypermodularizacją i zautomatyzowanym SDLC</p>

                <div class="badges">
                    <div class="badge">GitHub: tom-sapletta-com</div>
                    <div class="badge">LinkedIn: tom-sapletta-com</div>
                    <div class="badge">Portfolio: digitname.com</div>
                    <div class="badge">Apache 2.0 License</div>
                </div>
            </div>

            <div class="slide-footer">
                <div>GetLLM - Thank You!</div>
                <div>© 2024 Tom Sapletta - Apache 2.0 License</div>
            </div>
        </div>

    </div>

    <!-- Przycisk drukowania -->
    <button class="print-button no-print" onclick="window.print()">
        📄 Generuj PDF
    </button>

    <script>
        // Funkcja do przygotowania wydruku
        function preparePrint() {
            // Dodaj style specyficzne dla wydruku
            const printStyles = document.createElement('style');
            printStyles.textContent = `
                @media print {
                    @page {
                        size: A4;
                        margin: 1cm;
                    }

                    body {
                        font-size: 12pt;
                        line-height: 1.4;
                    }

                    .slide {
                        margin: 0;
                        padding: 15mm;
                        box-shadow: none !important;
                        border: none;
                    }

                    h1 { font-size: 24pt; }
                    h2 { font-size: 18pt; }
                    h3 { font-size: 14pt; }

                    .code-block {
                        font-size: 9pt;
                        line-height: 1.3;
                    }
                }
            `;
            document.head.appendChild(printStyles);
        }

        // Przygotuj do wydruku przy załadowaniu strony
        document.addEventListener('DOMContentLoaded', preparePrint);

        // Dodaj informacje o prezentacji
        document.title = 'GetLLM - Prezentacja PDF - ' + new Date().toLocaleDateString('pl-PL');
    </script>
</body>
</html>